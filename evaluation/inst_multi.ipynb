{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7588dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wjdrb\\anaconda3\\envs\\pptagent\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wjdrb\\anaconda3\\envs\\pptagent\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------  11.5/11.6 MB 60.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 55.9 MB/s eta 0:00:00\n",
      "Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 12.6/15.9 MB 56.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 52.9 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.0.2 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c680f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open('test_instructions.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "all_data = []\n",
    "for category, items in data.items():\n",
    "    for item in items:\n",
    "        item['category'] = category  # 카테고리 정보 추가\n",
    "        all_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edfb5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json_list_from_response(content):\n",
    "    if isinstance(content, list):\n",
    "        return content\n",
    "    if not isinstance(content, str):\n",
    "        raise TypeError(\"Expected string or list as input\")\n",
    "\n",
    "    # 1. Try to extract JSON inside triple backticks\n",
    "    code_block_match = re.search(r\"```json\\s*(.*?)```\", content, re.DOTALL)\n",
    "    if code_block_match:\n",
    "        json_str = code_block_match.group(1)\n",
    "    else:\n",
    "        bracket_match = re.search(r\"\\[.*\\]\", content, re.DOTALL)\n",
    "        if bracket_match:\n",
    "            json_str = bracket_match.group(0)\n",
    "        else:\n",
    "            raise ValueError(\"No JSON-like list found in response.\")\n",
    "\n",
    "    # 2. Escape inner double quotes inside each string entry\n",
    "    # Step 1: Split into individual entries\n",
    "    entries = re.findall(r'\"(.*?)\"', json_str, re.DOTALL)\n",
    "    if not entries:\n",
    "        raise ValueError(\"Failed to extract entries from raw string.\")\n",
    "\n",
    "    # Step 2: Escape internal quotes and rebuild the list\n",
    "    cleaned_entries = []\n",
    "    for entry in entries:\n",
    "        # Replace internal \" with \\\", and ensure it's a valid string\n",
    "        cleaned = entry.replace('\\\\\"', '\"')  # Remove any pre-escaped quotes\n",
    "        cleaned = cleaned.replace('\"', '\\\\\"')  # Escape any remaining quotes\n",
    "        cleaned_entries.append(f'\"{cleaned}\"')\n",
    "\n",
    "    cleaned_json = \"[\" + \",\\n\".join(cleaned_entries) + \"]\"\n",
    "\n",
    "    # 3. Parse JSON\n",
    "    return json.loads(cleaned_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c8b76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "def generate_similar_prompts(base_prompt, n=10):\n",
    "    system_prompt = (\n",
    "        \"You are an assistant that creates diverse, non-redundant prompts for PowerPoint slide editing. \"\n",
    "        \"Given a base prompt, generate {} alternative prompts that are functionally similar, but use different expressions or target different languages. \"\n",
    "        \"Ensure the results are distinct and not trivial rephrases.\".format(n)\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"Base prompt: {base_prompt}\\n\\nReturn a JSON list of {n} different, unique prompts. Give me a JSON.\"\n",
    "\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")   \n",
    "    retries = 3\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4o\",\n",
    "                instructions = system_prompt,\n",
    "                input = user_prompt,\n",
    "                temperature=0.2\n",
    "            )\n",
    "            content = response.output_text\n",
    "            #print(content)\n",
    "            try:\n",
    "                generated_prompts = extract_json_list_from_response(content)\n",
    "                if isinstance(generated_prompts, list) and len(generated_prompts) == n:\n",
    "                    return generated_prompts\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid response structure\")\n",
    "            except json.JSONDecodeError:\n",
    "                raise ValueError(\"Could not parse JSON\")\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            time.sleep(2)\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5649b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 8/58 [00:29<03:20,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Invalid response structure\n",
      "Attempt 2 failed: Invalid response structure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [04:20<00:00,  4.50s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: all_data = [{\"prompt\": \"Translate all visible text elements on ppt slide number {slide_num} into Japanese.\"}, ...]\n",
    "\n",
    "output = []\n",
    "\n",
    "for i in tqdm(range(len(all_data))):\n",
    "    input_prompt = all_data[i]['prompt']\n",
    "    generated = generate_similar_prompts(input_prompt, n=10)\n",
    "    output.append({\n",
    "        \"original\": input_prompt,\n",
    "        \"generated_variants\": generated\n",
    "    })\n",
    "\n",
    "# Save to file\n",
    "with open(\"augmented_prompts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4b738cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3818c0",
   "metadata": {},
   "source": [
    "58 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53791fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pptagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
